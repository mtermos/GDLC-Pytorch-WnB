{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
                "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
                "execution": {
                    "iopub.execute_input": "2024-08-24T12:01:21.407444Z",
                    "iopub.status.busy": "2024-08-24T12:01:21.407010Z",
                    "iopub.status.idle": "2024-08-24T12:01:29.827271Z",
                    "shell.execute_reply": "2024-08-24T12:01:29.826059Z",
                    "shell.execute_reply.started": "2024-08-24T12:01:21.407404Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "\n",
                "import os\n",
                "import random\n",
                "import socket\n",
                "import struct\n",
                "\n",
                "import networkx as nx\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "from src.dataset.dataset_info import datasets, cn_measures, network_features\n",
                "from src.graph.graph_measures import calculate_graph_measures, find_communities\n",
                "from src.graph.centralities import add_centralities\n",
                "from local_variables import local_datasets_path\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "multi_class = True\n",
                "\n",
                "sort_timestamp = False\n",
                "sort_after_partition = True\n",
                "\n",
                "use_port_in_address = False\n",
                "generated_ips = False\n",
                "\n",
                "validation_size = 0.1\n",
                "test_size = 0.1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'C:\\\\Users\\\\Administrateur\\\\Desktop\\\\datasets\\\\cic_ton_iot'"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# name = \"cic_ton_iot_5_percent\"\n",
                "# name = \"cic_ton_iot\"\n",
                "# name = \"cic_ids_2017_5_percent\"\n",
                "# name = \"cic_ids_2017\"\n",
                "name = \"cic_bot_iot\"\n",
                "# name = \"cic_ton_iot_modified\"\n",
                "# name = \"nf_ton_iotv2_modified\"\n",
                "# name = \"ccd_inid_modified\"\n",
                "# name = \"nf_uq_nids_modified\"\n",
                "# name = \"edge_iiot\"\n",
                "# name = \"nf_cse_cic_ids2018\"\n",
                "# name = \"nf_bot_iotv2\"\n",
                "# name = \"nf_uq_nids\"\n",
                "# name = \"x_iiot\"\n",
                "\n",
                "dataset = datasets[name]\n",
                "\n",
                "dataset_folder = os.path.join(local_datasets_path, name)\n",
                "dataset_folder"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'C:\\\\Users\\\\Administrateur\\\\Desktop\\\\datasets\\\\cic_ton_iot\\\\gdlc__multi_class__semisorted'"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "exp_type = \"gdlc\"\n",
                "\n",
                "if multi_class:\n",
                "    exp_type += \"__multi_class\"\n",
                "    \n",
                "if use_port_in_address:\n",
                "    exp_type += \"__ports\"\n",
                "    \n",
                "if generated_ips:\n",
                "    exp_type += \"__generated_ips\"\n",
                "    \n",
                "if sort_timestamp:\n",
                "    exp_type += \"__sorted\"\n",
                "elif sort_after_partition:\n",
                "    exp_type += \"__semisorted\"\n",
                "else:\n",
                "    exp_type += \"__unsorted\"\n",
                "    \n",
                "new_folder_path = os.path.join(dataset_folder, exp_type)\n",
                "new_folder_path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_parquet(os.path.join(dataset_folder, f\"{name}.parquet\"))\n",
                "if generated_ips:\n",
                "    df[dataset.src_ip_col] = df[dataset.src_ip_col].apply(lambda x: socket.inet_ntoa(struct.pack('>I', random.randint(0xac100001, 0xac1f0001))))\n",
                "if sort_timestamp:\n",
                "    df[dataset.timestamp_col] = pd.to_datetime(df[dataset.timestamp_col].str.strip(), format=dataset.timestamp_format)\n",
                "    df.sort_values(dataset.timestamp_col, inplace=True)\n",
                "if use_port_in_address:\n",
                "    df[dataset.src_port_col] = df[dataset.src_port_col].astype(float).astype(int).astype(str) # to remove the decimal point\n",
                "    df[dataset.src_ip_col] = df[dataset.src_ip_col] + ':' + df[dataset.src_port_col]\n",
                "\n",
                "    df[dataset.dst_port_col] = df[dataset.dst_port_col].astype(float).astype(int).astype(str) # to remove the decimal point\n",
                "    df[dataset.dst_ip_col] = df[dataset.dst_ip_col] + ':' + df[dataset.dst_port_col]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# G = nx.from_pandas_edgelist(\n",
                "#     df, source=dataset.src_ip_col, target=dataset.dst_ip_col, create_using=nx.DiGraph)\n",
                "# G.remove_nodes_from(list(nx.isolates(G)))\n",
                "# for node in G.nodes():\n",
                "#     G.nodes[node]['label'] = node\n",
                "# G1, part, communities = find_communities(G, verbose=True)\n",
                "# calculate_graph_measures(G, communities=communities, verbose=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "if multi_class:\n",
                "    y = df[dataset.class_num_col]\n",
                "else:\n",
                "    y = df[dataset.label_col]\n",
                "\n",
                "if sort_timestamp:\n",
                "    X_tr, X_test, y_tr, y_test = train_test_split(\n",
                "        df, y, test_size=test_size)\n",
                "    \n",
                "    X_train, X_val, y_train, y_val = train_test_split(\n",
                "        X_tr, y_tr, test_size=validation_size)\n",
                "else:\n",
                "    X_tr, X_test, y_tr, y_test = train_test_split(\n",
                "        df, y, test_size=test_size, random_state=13, stratify=y)\n",
                "    \n",
                "    X_train, X_val, y_train, y_val = train_test_split(\n",
                "        X_tr, y_tr, test_size=validation_size, random_state=13, stratify=y_tr)\n",
                "\n",
                "del df\n",
                "\n",
                "if sort_after_partition:\n",
                "    X_train[dataset.timestamp_col] = pd.to_datetime(X_train[dataset.timestamp_col].str.strip(), format=dataset.timestamp_format)\n",
                "    X_train.sort_values(dataset.timestamp_col, inplace=True)\n",
                "\n",
                "    X_val[dataset.timestamp_col] = pd.to_datetime(X_val[dataset.timestamp_col].str.strip(), format=dataset.timestamp_format)\n",
                "    X_val.sort_values(dataset.timestamp_col, inplace=True)\n",
                "    \n",
                "    X_test[dataset.timestamp_col] = pd.to_datetime(X_test[dataset.timestamp_col].str.strip(), format=dataset.timestamp_format)\n",
                "    X_test.sort_values(dataset.timestamp_col, inplace=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# os.makedirs(new_folder_path, exist_ok=True)\n",
                "# X_train.to_parquet(os.path.join(new_folder_path, \"training.parquet\"))\n",
                "# X_val.to_parquet(os.path.join(new_folder_path, \"validation.parquet\"))\n",
                "# X_test.to_parquet(os.path.join(new_folder_path, \"testing.parquet\"))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2024-08-24T12:01:38.979760Z",
                    "iopub.status.busy": "2024-08-24T12:01:38.979252Z",
                    "iopub.status.idle": "2024-08-24T12:01:39.036289Z",
                    "shell.execute_reply": "2024-08-24T12:01:39.035076Z",
                    "shell.execute_reply.started": "2024-08-24T12:01:38.979720Z"
                },
                "trusted": true
            },
            "outputs": [],
            "source": [
                "G_train = nx.from_pandas_edgelist(\n",
                "    X_train, source=dataset.src_ip_col, target=dataset.dst_ip_col, create_using=nx.DiGraph)\n",
                "G_train.remove_nodes_from(list(nx.isolates(G_train)))\n",
                "for node in G_train.nodes():\n",
                "    G_train.nodes[node]['label'] = node\n",
                "G1_train, part_train, communities_train = find_communities(G_train, verbose=True)\n",
                "calculate_graph_measures(G_train, communities=communities_train, verbose=True)\n",
                "\n",
                "G_val = nx.from_pandas_edgelist(\n",
                "    X_val, source=dataset.src_ip_col, target=dataset.dst_ip_col, create_using=nx.DiGraph)\n",
                "G_val.remove_nodes_from(list(nx.isolates(G_val)))\n",
                "for node in G_val.nodes():\n",
                "    G_val.nodes[node]['label'] = node\n",
                "G1_val, part_val, communities_val = find_communities(G_val, verbose=True)\n",
                "calculate_graph_measures(G_val, communities=communities_val, verbose=True)\n",
                "\n",
                "G_test = nx.from_pandas_edgelist(\n",
                "    X_test, source=dataset.src_ip_col, target=dataset.dst_ip_col, create_using=nx.DiGraph)\n",
                "G_test.remove_nodes_from(list(nx.isolates(G_test)))\n",
                "for node in G_test.nodes():\n",
                "    G_test.nodes[node]['label'] = node\n",
                "G1_test, part_test, communities_test = find_communities(G_test, verbose=True)\n",
                "calculate_graph_measures(G_test, communities=communities_test, verbose=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset.centralities_set = 2\n",
                "dataset.centralities_set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs(new_folder_path, exist_ok=True)\n",
                "\n",
                "print(\"===================\")\n",
                "print(\"training:\")\n",
                "add_centralities(df = X_train, new_path=os.path.join(new_folder_path, \"training.parquet\"), graph_path=None, dataset=dataset, cn_measures=cn_measures[dataset.centralities_set-1], network_features=network_features[dataset.centralities_set-1], G=G_train, communities=communities_train, G1=G1_train, part=part_train)\n",
                "\n",
                "print(\"===================\")\n",
                "print(\"validation:\")\n",
                "add_centralities(df = X_val, new_path=os.path.join(new_folder_path, \"validation.parquet\"), graph_path=None, dataset=dataset, cn_measures=cn_measures[dataset.centralities_set-1], network_features=network_features[dataset.centralities_set-1], G=G_val, communities=communities_val, G1=G1_val, part=part_val)\n",
                "\n",
                "print(\"===================\")\n",
                "print(\"testing:\")\n",
                "add_centralities(df = X_test, new_path=os.path.join(new_folder_path, \"testing.parquet\"), graph_path=None, dataset=dataset, cn_measures=cn_measures[dataset.centralities_set-1], network_features=network_features[dataset.centralities_set-1], G=G_test, communities=communities_test, G1=G1_test, part=part_test)"
            ]
        }
    ],
    "metadata": {
        "kaggle": {
            "accelerator": "none",
            "dataSources": [
                {
                    "datasetId": 4775518,
                    "sourceId": 8089266,
                    "sourceType": "datasetVersion"
                },
                {
                    "datasetId": 4775527,
                    "sourceId": 8089281,
                    "sourceType": "datasetVersion"
                }
            ],
            "isGpuEnabled": false,
            "isInternetEnabled": true,
            "language": "python",
            "sourceType": "notebook"
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
